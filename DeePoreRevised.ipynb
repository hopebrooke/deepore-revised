{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7EvQ0WKoNdmbFn6adCNta"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# REPEAT OF DEEPORE.PY WITH NEW AND REVISED FUNCTIONS\n","# ALL FUNCTIONS WILL BE COMMENTED TO OUTLINE WHICH ARE ORIGINAL, REVISED, OR NEW\n","# THE ORIGINAL DEEPORE FILE/LIBRARY WILL BE AVAILABLE FOR COMPARISON"],"metadata":{"id":"LvOAlbdAZswa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWR2B8EyZnEf"},"outputs":[],"source":["# ORIGINAL DEEPORE\n","import h5py\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D\n","from tensorflow.keras.models import Model\n","import os, sys\n","import matplotlib.pyplot as plt\n","from urllib.request import urlretrieve\n","import scipy.io as sio\n","from scipy.ndimage import distance_transform_edt as distance\n","import tensorflow.keras.backend as kb\n","# import cv2"]},{"cell_type":"code","source":["# REVISED DEEPORE\n","# Reason -> problem with float/int conversion\n","# Revision -> added int casting\n","def show_feature_maps(A):\n","    N=int(np.ceil(np.sqrt(A.shape[0])))\n","    f=plt.figure(figsize=(N*10,N*10))\n","    for I in range(A.shape[0]):\n","        plt.subplot(N,N,I+1)\n","        plt.imshow(normal(np.squeeze(A[I,:,:,:])))\n","        plt.axis('off')\n","    plt.show()\n","\n","    f.savefig('images/initial_feature_maps.png')"],"metadata":{"id":"nF1qsflFbKhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NEW FUNCTION\n","# Reason -> directs to correct slive vol func based on how many slices requested\n","def slicevol(A, n):\n","  if n == 1:\n","    slicevol_1(A)\n","  elif n == 2:\n","    slicevol_2(A)\n","  elif n == 3:\n","    slicevol_3(A)\n","  else:\n","    print(\"Error: Not a valid slice number.\")\n","\n","# ORIGINAL DEEPORE\n","def slicevol_1(A):\n","    A=np.squeeze(A)\n","    B=np.zeros((1,A.shape[0],A.shape[1],3))\n","    B[0,:,:,0]=A[int(A.shape[0]/2),:,:]\n","    B[0,:,:,1]=A[:,int(A.shape[1]/2),:]\n","    B[0,:,:,2]=A[:,:,int(A.shape[2]/2)]\n","    return B\n","\n","# REVISED DEEPORE\n","# Reason -> editing original slicevol to take 2 slices in each direction instead of 1\n","# Revision -> 2 slices taken from each direction at 1/3 and 2/3, rather than at 1/2\n","def slicevol_2(A):\n","    A=np.squeeze(A)\n","    B=np.zeros((1,A.shape[0],A.shape[1],6))\n","    # slices from front\n","    B[0,:,:,0]=A[int(A.shape[0]/3),:,:]\n","    B[0,:,:,1]=A[int(2 * A.shape[0]/3),:,:]\n","    # slices from left\n","    B[0,:,:,2]=A[:,int(A.shape[1]/3),:]\n","    B[0,:,:,3]=A[:,int(2 * A.shape[1]/3),:]\n","    # slices from top\n","    B[0,:,:,4]=A[:,:,int(A.shape[2]/3)]\n","    B[0,:,:,5]=A[:,:,int( 2 * A.shape[2]/3)]\n","    return B\n","\n","# REVISED DEEPORE\n","# Reason -> editing original slicevol to take 3 slices in each direction instead of 1\n","# Revision -> 3 slices taken from each direction at 1/4, 2/4 and 3/4, rather than at 1/2\n","def slicevol_3(A):\n","    A=np.squeeze(A)\n","    B=np.zeros((1,A.shape[0],A.shape[1],9))\n","    # slices from front\n","    B[0,:,:,0]=A[int(A.shape[0]/4),:,:]\n","    B[0,:,:,1]=A[int(2 * A.shape[0]/4),:,:]\n","    B[0,:,:,2]=A[int(3 * A.shape[0]/4),:,:]\n","    # slices from left\n","    B[0,:,:,3]=A[:,int(A.shape[1]/4),:]\n","    B[0,:,:,4]=A[:,int(2 * A.shape[1]/4),:]\n","    B[0,:,:,5]=A[:,int(3 * A.shape[1]/4),:]\n","    # slices from top\n","    B[0,:,:,6]=A[:,:,int(A.shape[2]/4)]\n","    B[0,:,:,7]=A[:,:,int( 2 * A.shape[2]/4)]\n","    B[0,:,:,8]=A[:,:,int( 3 * A.shape[2]/4)]\n","    return B"],"metadata":{"id":"BvmzeLLQbJ0Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NEW FUNCTION\n","# Reason -> directs to correct show entry func based on how many slices requested\n","def showentry(A, n):\n","  if n == 1:\n","    showentry_1(A)\n","  elif n == 2:\n","    showentry_2(A)\n","  elif n == 3:\n","    showentry_3(A)\n","  else:\n","    print(\"Error: Not a valid slice number.\")\n","\n","# REVISED DEEPORE\n","# Reason -> np.int deprecated\n","# Revision -> replaced np.int with int\n","def showentry_1(A):\n","    \"\"\"shows 3 slices of a volume data \"\"\"\n","    A=np.squeeze(A)\n","    plt.figure(num=None, figsize=(20, 8), dpi=80, facecolor='w', edgecolor='k')\n","    CM=plt.cm.viridis\n","    ax1=plt.subplot(1,3,1); plt.axis('off'); ax1.set_title('X mid-slice')\n","    plt.imshow(np.squeeze(A[int(A.shape[0]/2), :,:]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax2=plt.subplot(1,3,2); plt.axis('off'); ax2.set_title('Y mid-slice')\n","    plt.imshow(np.squeeze(A[:,int(A.shape[1]/2), :]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax3=plt.subplot(1,3,3); plt.axis('off'); ax3.set_title('Z mid-slice');\n","    plt.imshow(np.squeeze(A[:,:,int(A.shape[2]/2)]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    plt.savefig('images/First_entry.png')\n","\n","# REVISED DEEPORE\n","# Reason -> changing slice num means we need to change how the entries are shown\n","# Revision -> shows 2 slices in each direction, at 1/3 and 2/3 of the shape\n","def showentry_2(A):\n","    \"\"\"shows 6 slices of a volume data \"\"\"\n","    A=np.squeeze(A)\n","    plt.figure(num=None, figsize=(20, 14), dpi=80, facecolor='w', edgecolor='k')\n","    CM=plt.cm.viridis\n","    # X SLICES\n","    ax1=plt.subplot(2,3,1); plt.axis('off'); ax1.set_title('X mid-slice 1')\n","    plt.imshow(np.squeeze(A[int(A.shape[0]/3), :,:]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax2=plt.subplot(2,3,4); plt.axis('off'); ax2.set_title('X mid-slice 2')\n","    plt.imshow(np.squeeze(A[int(2 * A.shape[0]/3), :,:]), cmap=CM, interpolation='nearest')\n","    # Y SLICES\n","    ax3=plt.subplot(2,3,2); plt.axis('off'); ax3.set_title('Y mid-slice 1')\n","    plt.imshow(np.squeeze(A[:,int(A.shape[1]/3), :]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax4=plt.subplot(2,3,5); plt.axis('off'); ax4.set_title('Y mid-slice 2')\n","    plt.imshow(np.squeeze(A[:,int(2 * A.shape[1]/3), :]), cmap=CM, interpolation='nearest')\n","    # Z SLICES\n","    ax5=plt.subplot(2,3,3); plt.axis('off'); ax5.set_title('Z mid-slice 1');\n","    plt.imshow(np.squeeze(A[:,:,int(A.shape[2]/3)]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax6=plt.subplot(2,3,6); plt.axis('off'); ax6.set_title('Z mid-slice 2');\n","    plt.imshow(np.squeeze(A[:,:,int(2 * A.shape[2]/3)]), cmap=CM, interpolation='nearest')\n","    plt.savefig('images/First_entry_2.png')\n","\n","# REVISED DEEPORE\n","# Reason -> changing slice num means we need to change how the entries are shown\n","# Revision -> shows 3 slices in each direction, at 1/4, 2/4 and 3/4 of the shape\n","def showentry_3(A):\n","    \"\"\"shows 9 slices of a volume data \"\"\"\n","    A=np.squeeze(A)\n","    plt.figure(num=None, figsize=(20, 20), dpi=80, facecolor='w', edgecolor='k')\n","    CM=plt.cm.viridis\n","    # X SLICES\n","    ax1=plt.subplot(3,3,1); plt.axis('off'); ax1.set_title('X mid-slice 1')\n","    plt.imshow(np.squeeze(A[int(A.shape[0]/4), :,:]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax2=plt.subplot(3,3,4); plt.axis('off'); ax2.set_title('X mid-slice 2')\n","    plt.imshow(np.squeeze(A[int(2 * A.shape[0]/4), :,:]), cmap=CM, interpolation='nearest')\n","    ax3=plt.subplot(3,3,7); plt.axis('off'); ax3.set_title('X mid-slice 3')\n","    plt.imshow(np.squeeze(A[int(3 * A.shape[0]/4), :,:]), cmap=CM, interpolation='nearest')\n","    # Y SLICES\n","    ax4=plt.subplot(3,3,2); plt.axis('off'); ax4.set_title('Y mid-slice 1')\n","    plt.imshow(np.squeeze(A[:,int(A.shape[1]/4), :]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax5=plt.subplot(3,3,5); plt.axis('off'); ax5.set_title('Y mid-slice 2')\n","    plt.imshow(np.squeeze(A[:,int(2 * A.shape[1]/4), :]), cmap=CM, interpolation='nearest')\n","    ax6=plt.subplot(3,3,8); plt.axis('off'); ax6.set_title('Y mid-slice 3')\n","    plt.imshow(np.squeeze(A[:,int(3 * A.shape[1]/4), :]), cmap=CM, interpolation='nearest')\n","    # Z SLICES\n","    ax7=plt.subplot(3,3,3); plt.axis('off'); ax7.set_title('Z mid-slice 1');\n","    plt.imshow(np.squeeze(A[:,:,int(A.shape[2]/4)]), cmap=CM, interpolation='nearest')\n","    # plt.colorbar(orientation=\"horizontal\")\n","    ax8=plt.subplot(3,3,6); plt.axis('off'); ax8.set_title('Z mid-slice 2');\n","    plt.imshow(np.squeeze(A[:,:,int(2 * A.shape[2]/4)]), cmap=CM, interpolation='nearest')\n","    ax9=plt.subplot(3,3,9); plt.axis('off'); ax9.set_title('Z mid-slice 3');\n","    plt.imshow(np.squeeze(A[:,:,int(3 * A.shape[2]/4)]), cmap=CM, interpolation='nearest')\n","    plt.savefig('images/First_entry_3.png')"],"metadata":{"id":"fovnqfsDb2OH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NEW FUNCTION\n","# Reason -> directs to correct create dataset func based on how many slices requested\n","def create_compact_dataset(Path_complete,Path_compact, n):\n","  if n == 1:\n","    create_compact_dataset_1(Path_complete,Path_compact)\n","  elif n == 2:\n","    create_compact_dataset_2(Path_complete,Path_compact)\n","  elif n == 3:\n","    create_compact_dataset_3(Path_complete,Path_compact)\n","  else:\n","    print(\"Error: Not a valid slice number.\")\n","\n","# REVISED DEEPORE\n","# Reason -> needs to also know how many slices being requested in each dir (1, 2 or 3)\n","# Revision -> passes 1 as param to slicevol and ecl_distance\n","def create_compact_dataset_1(Path_complete,Path_compact):\n","    S=hdf_shapes(Path_complete,['X'])\n","    for I in range(S[0][0]):\n","        X=readh5slice(Path_complete,'X',[I])\n","        Y=readh5slice(Path_complete,'Y',[I])\n","        X=slicevol_1(X)\n","        X=ecl_distance_1(X)\n","        writeh5slice(X,Path_compact,'X',Shape=[128,128,3])\n","        writeh5slice(Y,Path_compact,'Y',Shape=[1515,1])\n","\n","# REVISED DEEPORE\n","# Reason -> if we change slice volume, we change how the compact dataset is created\n","# Revision -> changing parameters for writeh5slice() call from 3 to 6, passes 2 as param to slicevol and ecl_distance\n","def create_compact_dataset_2(Path_complete,Path_compact):\n","    S=hdf_shapes(Path_complete,['X'])\n","    for I in range(S[0][0]):\n","        X=readh5slice(Path_complete,'X',[I])\n","        Y=readh5slice(Path_complete,'Y',[I])\n","        X=slicevol_2(X)\n","        X=ecl_distance_2(X)\n","        writeh5slice(X,Path_compact,'X',Shape=[128,128,6])\n","        writeh5slice(Y,Path_compact,'Y',Shape=[1515,1])\n","\n","# REVISED DEEPORE\n","# Reason -> if we change slice volume, we change how the compact dataset is created\n","# Revision -> changing parameters for writeh5slice() call from 3 to 9, passes 2 as param to slicevol and ecl_distance\n","def create_compact_dataset_3(Path_complete,Path_compact):\n","    S=hdf_shapes(Path_complete,['X'])\n","    for I in range(S[0][0]):\n","        X=readh5slice(Path_complete,'X',[I])\n","        Y=readh5slice(Path_complete,'Y',[I])\n","        X=slicevol_3(X)\n","        X=ecl_distance_3(X)\n","        writeh5slice(X,Path_compact,'X',Shape=[128,128,9])\n","        writeh5slice(Y,Path_compact,'Y',Shape=[1515,1])"],"metadata":{"id":"kZcQ7a0ab1jF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NEW FUNCTION\n","# Reason -> directs to correct load model func based on how many slices requested\n","def loadmodel(n, ModelType=3):\n","  if n == 1:\n","    loadmodel_1(ModelType)\n","  elif n == 2:\n","    loadmodel_2(ModelType)\n","  elif n == 3:\n","    loadmodel_3(ModelType)\n","  else:\n","    print(\"Error: Not a valid slice number.\")\n","\n","# ORIGINAL DEEPORE\n","def loadmodel_1(ModelType=3): # model type 3 seems to be the better one\n","    Path='Model'+str(ModelType)+'.h5';\n","    MIN,MAX=np.load('minmax.npy')\n","    INPUT_SHAPE=[1,128,128,3];\n","    OUTPUT_SHAPE=[1,1515,1];\n","    model=modelmake(INPUT_SHAPE,OUTPUT_SHAPE,ModelType)\n","    model.load_weights(Path)\n","    return model\n","\n","# REVISED DEEPORE\n","# Reason -> load model needs to be updated for different slice volumes\n","# Revision -> adjusted array shape for 6 instead of 3\n","def loadmodel_2(ModelType=3):\n","    Path='Model'+str(ModelType)+'_2.h5';\n","    MIN,MAX=np.load('minmax.npy')\n","    INPUT_SHAPE=[1,128,128,6];\n","    OUTPUT_SHAPE=[1,1515,1];\n","    model=modelmake(INPUT_SHAPE,OUTPUT_SHAPE,ModelType)\n","    model.load_weights(Path)\n","    return model\n","\n","# REVISED DEEPORE\n","# Reason -> load model needs to be updated for different slice volumes\n","# Revision -> adjusted array shape for 6 instead of 3\n","def loadmodel_3(ModelType=3):\n","    Path='Model'+str(ModelType)+'_3.h5';\n","    MIN,MAX=np.load('minmax.npy')\n","    INPUT_SHAPE=[1,128,128,9];\n","    OUTPUT_SHAPE=[1,1515,1];\n","    model=modelmake(INPUT_SHAPE,OUTPUT_SHAPE,ModelType)\n","    model.load_weights(Path)\n","    return model"],"metadata":{"id":"nhHyFH3jadsW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NEW FUNCTION\n","# Reason -> directs to correct ecl dist func based on how many slices requested\n","def ecl_distance(A, n):\n","  if n == 1:\n","    ecl_distance_1(A)\n","  elif n == 2:\n","    ecl_distance_2(A)\n","  elif n == 3:\n","    ecl_distance_3(A)\n","  else:\n","    print(\"Error: Not a valid slice number.\")\n","\n","# ORIGINAL DEEPORE\n","def ecl_distance_1(A):\n","    B=np.zeros((A.shape[0],128,128,3))\n","    for I in range(A.shape[0]):\n","        for J in range(A.shape[3]):\n","            t=distance(np.squeeze(1-A[I,:,:,J]))-distance(np.squeeze(A[I,:,:,J]))\n","            # t=normalize(t)\n","            t=np.float32(t)/64\n","\n","            t[t>1]=1\n","            t[t<-1]=-1\n","\n","            t = MaxPooling2D((2, 2)) (np.reshape(t,(1,256,256,1)))\n","            t=np.float64(t)\n","            B[I,:,:,J]=np.squeeze(t)\n","    return B\n","\n","# REVISED DEEPORE\n","# Reason -> ecl distance calculations need to be changed for different slice volumes\n","# Revision -> adjusted shape arrays for 6 instead of 3\n","def ecl_distance_2(A):\n","    B=np.zeros((A.shape[0],128,128,6))\n","    for I in range(A.shape[0]):\n","        for J in range(A.shape[3]):\n","            t=distance(np.squeeze(1-A[I,:,:,J]))-distance(np.squeeze(A[I,:,:,J]))\n","            # t=normalize(t)\n","            t=np.float32(t)/64\n","\n","            t[t>1]=1\n","            t[t<-1]=-1\n","\n","            t = MaxPooling2D((2, 2)) (np.reshape(t,(1,256,256,1)))\n","            t=np.float64(t)\n","            B[I,:,:,J]=np.squeeze(t)\n","    return B\n","\n","# REVISED DEEPORE\n","# Reason -> ecl distance calculations need to be changed for different slice volumes\n","# Revision -> adjusted shape arrays for 9 instead of 3\n","def ecl_distance_3(A):\n","    B=np.zeros((A.shape[0],128,128,9))\n","    for I in range(A.shape[0]):\n","        for J in range(A.shape[3]):\n","            t=distance(np.squeeze(1-A[I,:,:,J]))-distance(np.squeeze(A[I,:,:,J]))\n","            # t=normalize(t)\n","            t=np.float32(t)/64\n","\n","            t[t>1]=1\n","            t[t<-1]=-1\n","\n","            t = MaxPooling2D((2, 2)) (np.reshape(t,(1,256,256,1)))\n","            t=np.float64(t)\n","            B[I,:,:,J]=np.squeeze(t)\n","    return B\n"],"metadata":{"id":"Xtd0iDtRbKcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def check_get(url,File_Name):\n","    def download_callback(blocknum, blocksize, totalsize):\n","        readsofar = blocknum * blocksize\n","        if totalsize > 0:\n","            percent = readsofar * 1e2 / totalsize\n","            s = \"\\r%5.1f%% %*d MB / %d MB\" % (\n","                percent, len(str(totalsize)), readsofar/1e6, totalsize/1e6)\n","            sys.stderr.write(s)\n","            if readsofar >= totalsize: # near the end\n","                sys.stderr.write(\"\\n\")\n","        else: # total size is unknown\n","            sys.stderr.write(\"read %d\\n\" % (readsofar,))\n","    if not os.path.isfile(File_Name):\n","        ans=input('You dont have the file \"' +File_Name +'\". Do you want to download it? (Y/N) ')\n","        if ans=='Y' or ans=='y' or ans=='yes' or ans=='Yes' or ans=='YES':\n","            print('Beginning file download. This might take several minutes.')\n","            urlretrieve(url,File_Name,download_callback)\n","    else:\n","        print('File \"' +File_Name +'\" is detected on your machine.'  )"],"metadata":{"id":"QfB2uY1naBiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def shuf(L):\n","    import random\n","    random.shuffle(L)\n","    return L"],"metadata":{"id":"gGoMMGVZaQBI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def WMSE(y_actual,y_pred): # weighted MSE loss\n","    w=np.ones((1,1515))\n","    w[:,15:]=.01\n","    w=np.float32(w)\n","    w=tf.tile(w, [tf.shape(y_pred)[0],1])\n","    loss=kb.square(y_actual-y_pred)\n","    loss=tf.multiply(loss,w)\n","    return loss"],"metadata":{"id":"R4zzkmRqaSLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def WBCE(y_actual,y_pred): # weighted binary crossentropy loss\n","    w=np.ones((1,1515))\n","    w[:,15:]=.01\n","    w=np.float32(w)\n","    w=tf.tile(w, [tf.shape(y_pred)[0],1])\n","    loss=kb.square(y_actual-y_pred)\n","    loss=y_actual*(-tf.math.log(y_pred))+(1-y_actual)*(-tf.math.log(1-y_pred))\n","    loss=tf.multiply(loss,w)\n","    return loss"],"metadata":{"id":"nLmpCErCaXxx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE MODELS\n","def DeePore1(INPUT_SHAPE,OUTPUT_SHAPE):\n","    # variable filters / 3 convs\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (8, 8), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (4, 4), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (2, 2), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    f=tf.keras.layers.Flatten()(p3)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    optim=tf.keras.optimizers.RMSprop(1e-5)\n","    model.compile(optimizer=optim, loss='mse', metrics=['mse'])\n","    return model\n","def DeePore2(INPUT_SHAPE,OUTPUT_SHAPE):\n","    # variable filters / 4 convs\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (8, 8), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (4, 4), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (2, 2), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    c4 = Conv2D(24, (2, 2), kernel_initializer='he_normal', padding='same') (p3)\n","    p4 = MaxPooling2D((2, 2)) (c4)\n","    f=tf.keras.layers.Flatten()(p4)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    optim=tf.keras.optimizers.RMSprop(1e-5)\n","    model.compile(optimizer=optim, loss='mse', metrics=['mse'])\n","    return model\n","def DeePore3(INPUT_SHAPE,OUTPUT_SHAPE):\n","    # fixed filter size/ 3 convs\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(12, (3, 3), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(24, (3, 3), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(36, (3, 3), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    f=tf.keras.layers.Flatten()(p3)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    optim=tf.keras.optimizers.RMSprop(1e-5)\n","    model.compile(optimizer=optim, loss='mse', metrics=['mse'])\n","    return model\n","def DeePore4(INPUT_SHAPE,OUTPUT_SHAPE):\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (8, 8), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (4, 4), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (2, 2), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    f=tf.keras.layers.Flatten()(p3)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    optim=tf.keras.optimizers.RMSprop(1e-5)\n","    model.compile(optimizer=optim, loss=WMSE, metrics=['mse'])\n","    return model\n","def DeePore5(INPUT_SHAPE,OUTPUT_SHAPE):\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (8, 8), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (4, 4), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (2, 2), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    c4 = Conv2D(24, (2, 2), kernel_initializer='he_normal', padding='same') (p3)\n","    p4 = MaxPooling2D((2, 2)) (c4)\n","    f=tf.keras.layers.Flatten()(p4)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    optim=tf.keras.optimizers.RMSprop(1e-5)\n","    model.compile(optimizer=optim, loss=WMSE, metrics=['mse'])\n","    return model\n","def DeePore6(INPUT_SHAPE,OUTPUT_SHAPE):\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(12, (3, 3), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(24, (3, 3), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(36, (3, 3), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    f=tf.keras.layers.Flatten()(p3)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    optim=tf.keras.optimizers.RMSprop(1e-5)\n","    model.compile(optimizer=optim, loss=WMSE, metrics=['mse'])\n","    return model\n","def DeePore7(INPUT_SHAPE,OUTPUT_SHAPE):\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (8, 8), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (4, 4), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (2, 2), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    f=tf.keras.layers.Flatten()(p3)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])\n","    return model\n","def DeePore8(INPUT_SHAPE,OUTPUT_SHAPE):\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (3, 3), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (3, 3), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (3, 3), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    f=tf.keras.layers.Flatten()(p3)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])\n","    return model\n","def DeePore9(INPUT_SHAPE,OUTPUT_SHAPE):\n","    inputs = Input(INPUT_SHAPE[1:])\n","    c1 = Conv2D(6, (3, 3), kernel_initializer='he_normal', padding='same') (inputs)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    c2 = Conv2D(12, (3, 3), kernel_initializer='he_normal', padding='same') (p1)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    c3 = Conv2D(18, (3, 3), kernel_initializer='he_normal', padding='same') (p2)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    c4 = Conv2D(24, (3, 3), kernel_initializer='he_normal', padding='same') (p3)\n","    p4 = MaxPooling2D((2, 2)) (c4)\n","    f=tf.keras.layers.Flatten()(p4)\n","    d1=tf.keras.layers.Dense(1515, activation=tf.nn.leaky_relu)(f)\n","    d2=tf.keras.layers.Dense(1515, activation=tf.nn.sigmoid)(d1)\n","    outputs=d2\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    model.compile(optimizer='adam', loss=WBCE, metrics=['mse'])\n","    return model\n","\n","def modelmake(INPUT_SHAPE,OUTPUT_SHAPE,ModelType):\n","    if ModelType==1:\n","        model=DeePore1(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==2:\n","        model=DeePore2(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==3:\n","        model=DeePore3(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==4:\n","        model=DeePore4(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==5:\n","        model=DeePore5(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==6:\n","        model=DeePore6(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==7:\n","        model=DeePore7(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==8:\n","        model=DeePore8(INPUT_SHAPE,OUTPUT_SHAPE)\n","    if ModelType==9:\n","        model=DeePore9(INPUT_SHAPE,OUTPUT_SHAPE)\n","    return model"],"metadata":{"id":"v7tsNJHIacrY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def prep(Data):\n","    print('Cheching the data for outliers. Please wait...')\n","    List=[]\n","    with h5py.File(Data,'r') as f:\n","        length=f['X'].shape[0]\n","        MIN=np.ones((f['Y'].shape[1],1))*1e7\n","        MAX=-MIN\n","        counter=0\n","        for I in range(length):\n","            t2=f['Y'][counter,...]\n","            y=t2.astype('float32')\n","            D=int(np.sum(np.isnan(y)))+int(np.sum(np.isinf(y)))+int(y[1]>120)+int(y[4]>1.8)+int(y[0]<1e-4)+int(y[2]<1e-5)+int(y[14]>.7)\n","\n","            if D>0:\n","                pass\n","            else:\n","                List=np.append(List,counter)\n","                y[0:15]=np.log10(y[0:15]) # applying log10 to handle range of order of magnitudes\n","                maxid=np.argwhere(y>MAX)\n","                minid=np.argwhere(y<MIN)\n","                MAX[maxid[:,0]]=y[maxid[:,0]]\n","                MIN[minid[:,0]]=y[minid[:,0]]\n","            if counter % 100==0:\n","                print('checking sample'+str(counter))\n","            counter=counter+1\n","        Singles=15\n","        for I in range(15):\n","            MAX[Singles+100*I:Singles+100*(I+1)]=np.max(MAX[Singles+100*I:Singles+100*(I+1)])\n","            MIN[Singles+100*I:Singles+100*(I+1)]=np.min(MIN[Singles+100*I:Singles+100*(I+1)])\n","    np.save('minmax.npy',[MIN,MAX])\n","    return List"],"metadata":{"id":"TAlUuPQBaczI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def gener(batch_size,Data,List,MIN,MAX):\n","    with h5py.File(Data,'r') as f:\n","        length=len(List)\n","        samples_per_epoch = length\n","        number_of_batches = int(samples_per_epoch/batch_size)\n","        counter=0\n","        while 1:\n","            t1=f['X'][np.int32(np.sort(List[batch_size*counter:batch_size*(counter+1)])),...]\n","            t2=f['Y'][np.int32(np.sort(List[batch_size*counter:batch_size*(counter+1)])),...]\n","            X_batch=t1.astype('float32')/128\n","            y_batch=t2.astype('float32')\n","            y_batch=np.reshape(y_batch,(y_batch.shape[0],y_batch.shape[1]))\n","            y_batch[:,0:15]=np.log10(y_batch[:,0:15])\n","            Min=np.tile(np.transpose(MIN),(batch_size,1))\n","            Max=np.tile(np.transpose(MAX),(batch_size,1))\n","            y_batch=(y_batch-Min)/(Max-Min)\n","            counter += 1\n","            ids=shuf(np.arange(np.shape(y_batch)[0]))\n","            X_batch=X_batch[ids,...]\n","            y_batch=y_batch[ids,...]\n","            # print(ids)\n","            yield X_batch,y_batch\n","            if counter >= number_of_batches: #restart counter to yeild data in the next epoch as well\n","                counter = 0"],"metadata":{"id":"U0GN1KmwadMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def hdf_shapes(Name,Fields):\n","    # Fields is list of hdf file fields\n","    Shape = [[] for _ in range(len(Fields))]\n","    with h5py.File(Name, 'r') as f:\n","        for I in range(len(Fields)):\n","            Shape[I]=f[Fields[I]].shape\n","    return Shape"],"metadata":{"id":"y2PG4bedadWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def now():\n","    import datetime\n","    d1 = datetime.datetime(1, 1, 1)\n","    d2 = datetime.datetime.now()\n","    d=d2-d1\n","    dd=d.days+d.seconds/(24*60*60)+d.microseconds/(24*60*60*1e6)+367\n","    return dd\n","def nowstr():\n","    from datetime import datetime\n","    now = datetime.now()\n","    return now.strftime(\"%d-%b-%Y %H.%M.%S\")"],"metadata":{"id":"pdmmoIOKadeh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","\n","def trainmodel(DataName,TrainList,EvalList,retrain=0,reload=0,epochs=100,batch_size=100,ModelType=9):\n","    from tensorflow.keras.callbacks import ModelCheckpoint\n","    MIN,MAX=np.load('minmax.npy')\n","    SaveName='Model'+str(ModelType)+'.h5';\n","    INPUT_SHAPE,OUTPUT_SHAPE =hdf_shapes(DataName,('X','Y'));\n","    OUTPUT_SHAPE=[1,1]\n","    # callbacks\n","    timestr=nowstr()\n","    LogName='log_'+timestr+'_'+'Model'+str(ModelType)\n","    filepath=SaveName\n","    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1,save_freq=50, save_best_only=True, mode='min')\n","    with open(\"Logs/\"+LogName+\".txt\", \"wt\") as f:\n","        f.write('# Path to train file: \\n')\n","        f.write(DataName +'\\n')\n","        f.write('# Start time: \\n')\n","        f.write(timestr +'\\n')\n","        nowstr()\n","        st='# Training loss'\n","        spa=' ' * (40-len(st))\n","        st=st+spa+'Validation loss'\n","        f.write(st+'\\n')\n","\n","    class MyCallback(tf.keras.callbacks.Callback):\n","        def __init__(self):\n","            self.val_loss_=None\n","            self.start_time=now()\n","        def on_batch_end(self, batch, logs=None):\n","            if self.val_loss_==None:\n","                self.val_loss_=logs['mse']\n","            with open(\"Logs/\"+LogName+\".txt\", \"a\") as f:\n","                st=str(logs['mse'])\n","                spa=' ' * (40-len(st))\n","                st=st+spa+str(self.val_loss_)\n","                f.write(st+'\\n')\n","        def on_test_batch_end(self,batch, logs=None):\n","            self.val_loss_=logs['mse']\n","    callbacks_list = [checkpoint,MyCallback()]\n","    callbacks_list = [checkpoint]\n","    callbacks_list = []\n","    callbacks_list = [MyCallback()]\n","    # end of callbacks\n","    model=modelmake(INPUT_SHAPE,OUTPUT_SHAPE,ModelType)\n","\n","\n","    if retrain:\n","        if reload:\n","            model.load_weights(SaveName)\n","\n","        model.fit(gener(batch_size,DataName,TrainList,MIN,MAX), epochs=epochs,steps_per_epoch=int(len(TrainList)/batch_size),\n","                  validation_data=gener(batch_size,DataName,EvalList,MIN,MAX),validation_steps=int(len(EvalList)/batch_size),callbacks=callbacks_list)\n","        model.save_weights(SaveName);\n","    else:\n","        model.load_weights(SaveName)\n","    return model\n"],"metadata":{"id":"_8tFOEmkadlm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def splitdata(List):\n","    N=np.int32([0,len(List)*.8,len(List)*.9,len(List)])\n","    TrainList=List[N[0]:N[1]]\n","    EvalList=List[N[1]:N[2]]\n","    TestList=List[N[2]:N[3]]\n","    return TrainList, EvalList, TestList"],"metadata":{"id":"UC6U2oojadx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def testmodel(model,DataName,TestList,ModelType=3):\n","    MIN,MAX=np.load('minmax.npy')\n","    G=gener(len(TestList),DataName,TestList,MIN,MAX)\n","    L=next(G)\n","    x=L[0]\n","    y=L[1]\n","    y2=model.predict(L[0])\n","    print('\\n# Evaluate on '+ str(TestList.shape[0]) + ' test data')\n","    model.evaluate(x,y,batch_size=50)\n","    #  Denormalize the predictions\n","    MIN=np.reshape(MIN,(1,y.shape[1]))\n","    MAX=np.reshape(MAX,(1,y.shape[1]))\n","    y=np.multiply(y,(MAX-MIN))+MIN\n","    y2=np.multiply(y2,(MAX-MIN))+MIN\n","    y[:,0:15]=10**y[:,0:15]\n","    y2[:,0:15]=10**y2[:,0:15]\n","\n","    # save test results as mat file for postprocessing with matlab\n","    import scipy.io as sio\n","    sio.savemat('Tested_Data_Model'+str(ModelType)+'.mat',{'y':y,'y2':y2})\n","    # #  Show prediction of 15 single-value features\n","    fig=plt.figure(figsize=(30,40))\n","    plt.rcParams.update({'font.size': 30})\n","    with open('VarNames.txt') as f:\n","        VarNames = list(f)\n","    for I in range(15):\n","        ax = fig.add_subplot(5,3,I+1)\n","        X=y[:,I]\n","        Y=y2[:,I]\n","        plt.scatter(X,Y)\n","        plt.ylabel('Predicted')\n","        plt.xlabel('Ground truth')\n","        plt.tick_params(direction=\"in\")\n","        plt.text(.5,.9,VarNames[I],horizontalalignment='center',transform=ax.transAxes)\n","        plt.xlim(np.min(X),np.max(X))\n","        plt.ylim(np.min(Y),np.max(Y))\n","        if I==0:\n","            ax.set_yscale('log')\n","            ax.set_xscale('log')\n","    plt.savefig('images/Single-value_Features.png')"],"metadata":{"id":"rgUMCksuad4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def mat2np(Name): # load the MATLAB array as numpy array\n","    B=sio.loadmat(Name)\n","    return B['A']"],"metadata":{"id":"sdWaGscWbJs0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# REVISED DEEPORE\n","# Reason -> edited ecl_dist so it needs paramater for slices\n","# Revision -> passes parameter to ecl_distance\n","def feedsampledata(A=None,FileName=None):\n","    if FileName!=None:\n","        extention=os.path.splitext(FileName)[1]\n","    else:\n","        extention=''\n","    if extention=='.mat':\n","        # A=mat2np(FileName)\n","        import scipy.io as sio\n","        A=sio.loadmat(FileName)['A']\n","    if extention=='.npy':\n","        A=np.load(FileName)\n","    if extention=='.npz':\n","        A=np.load(FileName)['A']\n","    if extention=='.npy' or extention=='.mat' or extention=='.npz' or FileName==None:\n","        if len(A.shape)==3:\n","\n","            A=np.int8(A!=0)\n","            LO,HI=makeblocks(A.shape,w=256,ov=.1)\n","            N=len(HI[0])*len(HI[1])*len(HI[2]) # number of subsamples\n","            AA=np.zeros((N,256,256,3))\n","            a=0\n","            for I in range(len(LO[0])):\n","                for J in range(len(LO[1])):\n","                    for K in range(len(LO[2])):\n","                        temp=A[LO[0][I]:HI[0][I],LO[1][J]:HI[1][J],LO[2][K]:HI[2][K]]\n","                        temp1=np.squeeze(temp[int(temp.shape[0]/2),:,:]);\n","                        temp2=np.squeeze(temp[:,int(temp.shape[1]/2),:]);\n","                        temp3=np.squeeze(temp[:,:,int(temp.shape[2]/2)]);\n","                        AA[a,...]=np.stack((temp1,temp2,temp3),axis=2)\n","                        a=a+1\n","    if extention=='.png' or extention=='.jpg' or extention=='.bmp':\n","        A=plt.imread(FileName)\n","        if len(A.shape)!=2:\n","            print('Converting image to grayscale...')\n","            A=np.mean(A,axis=2)\n","            print('Converting image to binary...')\n","            import cv2\n","            ret,A = cv2.threshold(A,127,255,cv2.THRESH_BINARY)\n","        A=np.int8(A!=0)\n","        LO,HI=makeblocks(A.shape,w=256,ov=.1)\n","        N=len(HI[0])*len(HI[1]) # number of subsamples\n","        AA=np.zeros((N,256,256,3))\n","        a=0\n","        for I in range(len(LO[0])):\n","            for J in range(len(LO[1])):\n","                temp=A[LO[0][I]:HI[0][I],LO[1][J]:HI[1][J]]\n","                AA[a,...]=np.stack((temp,np.flip(temp,axis=0),np.flip(temp,axis=1)),axis=2)\n","                a=a+1\n","    if FileName==None:\n","        if len(A.shape)==2:\n","            A=np.int8(A!=0)\n","            LO,HI=makeblocks(A.shape,w=256,ov=.1)\n","            N=len(HI[0])*len(HI[1]) # number of subsamples\n","            AA=np.zeros((N,256,256,3))\n","            a=0\n","            for I in range(len(LO[0])):\n","                for J in range(len(LO[1])):\n","                    temp=A[LO[0][I]:HI[0][I],LO[1][J]:HI[1][J]]\n","                    AA[a,...]=np.stack((temp,np.flip(temp,axis=0),np.flip(temp,axis=1)),axis=2)\n","                    a=a+1\n","\n","    B=ecl_distance(AA, 1)\n","    return B"],"metadata":{"id":"MtaY-JEIbKEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def writeh5slice(A,FileName,FieldName,Shape):\n","    # example: writeh5slice(A,'test3.h5','X',Shape=[70,70,1])\n","    D=len(Shape)\n","    if D==2:\n","         maxshape=(None,Shape[0],Shape[1])\n","         Shape0=(1,Shape[0],Shape[1])\n","         A=np.reshape(A,Shape0)\n","    if D==3:\n","         maxshape=(None,Shape[0],Shape[1],Shape[2])\n","         Shape0=(1,Shape[0],Shape[1],Shape[2])\n","         A=np.reshape(A,Shape0)\n","    if D==4:\n","         maxshape=(None,Shape[0],Shape[1],Shape[2],Shape[3])\n","         Shape0=(1,Shape[0],Shape[1],Shape[2],Shape[3])\n","         A=np.reshape(A,Shape0)\n","    try:\n","        with h5py.File(FileName, \"r\") as f:\n","            arr=f[FieldName]\n","        with h5py.File(FileName, \"a\") as f:\n","            arr=f[FieldName]\n","            Slice=arr.shape[0]\n","            arr.resize(arr.shape[0]+1, axis=0)\n","            arr[Slice,...]=A\n","        print('writing slice '+ str(Slice))\n","    except:\n","        with h5py.File(FileName, \"a\") as f:\n","            f.create_dataset(FieldName, Shape0,maxshape=maxshape, chunks=True,dtype=A.dtype,compression=\"gzip\", compression_opts=5)\n","            f[FieldName][0,...]=A"],"metadata":{"id":"SwZv_QQqbKLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def normalize(A):\n","    A_min = np.min(A)\n","    return (A-A_min)/(np.max(A)-A_min)\n","def normal(A):\n","    A_min = np.min(A)\n","    return (A-A_min)/(np.max(A)-A_min)"],"metadata":{"id":"Jd41inmrbKRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def predict(model,A,res=5):\n","    MIN,MAX=np.load('minmax.npy')\n","    y=model.predict(A)\n","    MIN=np.reshape(MIN,(1,y.shape[1]))\n","    MAX=np.reshape(MAX,(1,y.shape[1]))\n","    y=np.multiply(y,(MAX-MIN))+MIN\n","    y[:,0:15]=10**y[:,0:15]\n","    # y[:,1]=10**y[:,1]\n","    y=np.mean(y,axis=0)\n","    val=y[0:15]\n","    val[0]=val[0]*res*res\n","    val[3]=val[3]/res/res/res\n","    val[10]=val[10]/res\n","    val[6]=val[6]*res\n","    val[7]=val[7]*res\n","    val[8]=val[8]*res\n","    val[13]=val[13]*res\n","    d=100\n","    output=val\n","    for I in range(15):\n","        func=y[I*d+15:(I+1)*d+15]\n","        if I in [19,20,21,22,23,24,29]:\n","            func=func*res\n","        if I in [18]:\n","            func=func/res\n","        if I in [25]:\n","            func=func*res*res\n","        output=np.append(output,func)\n","    return output"],"metadata":{"id":"4fqo_2l0bKXX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def makeblocks(SS,n=None,w=None,ov=0):\n","    # w is the fixed width of the blocks and n is the number of blocks\n","    # if the number be high while w is fixed, blocks start to overlap and ov is between 0 to 1 gets desired overlapping degree\n","    # example:dp.makeblocks([100,200],w=16,ov=.1)\n","    HI=[]\n","    LO=[]\n","    for S in SS:\n","        if w==None and n!=None:\n","            mid=np.ceil(np.linspace(0,S,n+1));\n","            lo=mid; lo=np.delete(lo,-1);\n","            hi=mid; hi=np.delete(hi,0);\n","        if w!=None and n!=None:\n","            mid=np.ceil(np.linspace(0,S-w,n));\n","            lo=mid;\n","            hi=mid+w\n","        if w!=None and n==None: # good for image translation\n","            mid=np.asarray(np.arange(0,S,int(w*(1-ov))))\n","            lo=mid;\n","            hi=mid+w\n","            p=np.argwhere(hi>S)\n","            if len(p)>0:\n","                diff=hi[p]-S\n","                hi[p]=S\n","                lo[p]=lo[p]-diff\n","                hi=np.unique(hi)\n","                lo=np.unique(lo)\n","        HI.append(hi)\n","        LO.append(lo)\n","    return LO,HI"],"metadata":{"id":"Uwf0vmAjbKlZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def prettyresult(vals,FileName,units='um',verbose=1):\n","    vals=np.squeeze(vals)\n","    with open('VarNames.txt') as f:\n","        VarNames = list(f)\n","    b=np.round(vals[0:15],7)\n","    f = open(FileName, 'w')\n","    f.write('DeePore output results including 15 single-value' +'\\n'+ 'paramters, 4 functions and 11 distributions'+'\\n')\n","    f.write('_' * 50+'\\n')\n","    f.write('        ### Single-value parameters ###'+'\\n')\n","    f.write('_' * 50+'\\n')\n","    f.write('\\n')\n","    t='Properties'\n","    spa=' ' * (40-len(t))\n","    f.write(t+spa+'Value'+'\\n')\n","    f.write('-' * 50+'\\n')\n","    for i in range(len(b)):\n","        t=VarNames[i].strip()\n","        if units=='um':\n","            t=t.replace('px','um')\n","        spa=' ' * (40-len(t))\n","        results=t +spa+str(b[i])+'\\n'\n","        f.write(results)\n","    f.write('\\n')\n","    f.write('_' * 50+'\\n')\n","    f.write('       ### Functions and distributions ###'+'\\n')\n","    f.write('_' * 50+'\\n')\n","    for I in range(15):\n","        multiplier=1\n","        t=VarNames[I+15].strip()\n","        if units=='um':\n","            t=t.replace('px','um')\n","        f.write('\\n')\n","        f.write('\\n')\n","        f.write('# '+t+'\\n')\n","        f.write('-' * 50+'\\n')\n","        xlabel='Cumulative probability'\n","        if I+15 in [15,16,17]:\n","            xlabel='Wetting-sat (Sw)'\n","        if I+15 in [18]:\n","            xlabel='lag (px)'\n","            multiplier=50\n","        spa=' ' * (40-len(xlabel))\n","        f.write(xlabel+spa+'Value'+'\\n')\n","        f.write('-' * 50+'\\n')\n","        shift=I*100+15\n","        for J in range(100):\n","            t=str(np.round((J*.01+.01)*multiplier,2))\n","            spa=' ' * (40-len(t))\n","            f.write(t+spa+str(np.round(vals[J+shift],7))+'\\n')\n","    f.close()\n","    a=0\n","    if verbose:\n","        print('\\n')\n","        with open(FileName,\"r\") as f:\n","            for line in f:\n","                print(line)\n","                a=a+1\n","                if a>23:\n","                    print('-' * 50+'\\n')\n","                    print('To see all the results please refer to this file: \\n')\n","                    print(FileName+'\\n')\n","                    break"],"metadata":{"id":"E2F_kgO9bLHB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def readh5slice(FileName,FieldName,Slices):\n","    with h5py.File(FileName, \"r\") as f:\n","         A=f[FieldName][np.sort(Slices),...]\n","    return A"],"metadata":{"id":"2_-YAR7kbLMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ORIGINAL DEEPORE\n","def parfor(func,values):\n","    # example\n","    # def calc(I):\n","    #     return I*2\n","    # px.parfor(calc,[1,2,3])\n","    N=len(values)\n","    from joblib import Parallel, delayed\n","    from tqdm import tqdm\n","    Out = Parallel(n_jobs=-1)(delayed(func)(k) for k in tqdm(range(1,N+1)))\n","    return Out"],"metadata":{"id":"X-WSYpa1b2om"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mjDPsAp7b3an"},"execution_count":null,"outputs":[]}]}